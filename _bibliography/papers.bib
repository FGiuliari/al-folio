---
---
@inproceedings{giuliari2023positional,
      title={Positional Diffusion: Ordering Unordered Sets with Diffusion Probabilistic Models}, 
      author={Francesco Giuliari and Gianluca Scarpellini and Stuart James and Yiming Wang and Alessio Del Bue},
      year={2023},
      eprint={2303.11120},
      selected={true},
      booktitle={ArXiv},
      abbr={ArXiv},
      bibtex_show={true},
      website={https://github.com/IIT-PAVIS/Positional_Diffusion},
      arxiv={2303.11120},
      primaryClass={cs.CV}
}

@inproceedings{giuliari2022SpatialCommonsense,
  title={Spatial Commonsense Graph for Object localisation in Partial Scenes},
  author={Giuliari, Francesco and Skenderi, Geri and Cristani, Marco and Wang, Yiming and Del Bue, Alessio},
  booktitle={CVPR},
  abbr={CVPR},
  year={2022},
  selected={true},
  website={/projects/SpatialCommonsenseGraph},
  arxiv={2203.05380}
}

@inproceedings{Godi2018UnderstandingDA,
  title={Understanding Deep Architectures by Visual Summaries},
  author={Marco Godi and Marco Carletti and Maya Aghaei and Francesco Giuliari and Marco Cristani},
  booktitle={BMVC},
  year={2018},
  bibtex_show={true},
  arxiv={1801.09103},
  abbr={BMVC}
  
}
@inproceedings{wang2020pomp,
  title={POMP: Pomcp-based Online Motion Planning for active visual search in indoor environments},
  author={Wang, Yiming and Giuliari, Francesco and Berra, Riccardo and Castellini, Alberto and Del Bue, Alessio and Farinelli, Alessandro and Cristani, Marco and Setti, Francesco},
  booktitle={BMVC},
  year={2020},
  bibtex_show={true},
  arxiv={2009.08140},
  abbr={BMVC}
}

@inproceedings{giuliari2021pomp++,
  title={POMP++: Pomcp-based Active Visual Search in unknown indoor environments},
  author={Giuliari, Francesco and Castellini, Alberto and Berra, Riccardo and Del Bue, Alessio and Farinelli, Alessandro and Cristani, Marco and Setti, Francesco and Wang, Yiming},
  booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={1523--1530},
  organization={IEEE},
  year={2021},
  selected={true},
  bibtex_show={true},
  arxiv={2107.00914},
  abbr={IROS}
}

@inproceedings{giuliari2021transformer,
  title={Transformer networks for trajectory forecasting},
  author={Giuliari, Francesco and Hasan, Irtiza and Cristani, Marco and Galasso, Fabio},
  booktitle={2020 25th International Conference on Pattern Recognition (ICPR)},
  pages={10335--10342},
  year={2020},
  organization={IEEE},
  selected={true},
  bibtex_show={true},
  arxiv={2003.08111},
  abbr={ICPR}
}

@article{FRANCO2023109372,
title = {Under the hood of transformer networks for trajectory forecasting},
journal = {Pattern Recognition},
volume = {138},
pages = {109372},
year = {2023},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2023.109372},
url = {https://www.sciencedirect.com/science/article/pii/S0031320323000730},
author = {Luca Franco and Leonardo Placidi and Francesco Giuliari and Irtiza Hasan and Marco Cristani and Fabio Galasso},
keywords = {Trajectory forecasting, Human behavior, Transformer networks, BERT, Multi-modal future prediction},
abstract = {Transformer Networks have established themselves as the de-facto state-of-the-art for trajectory forecasting but there is currently no systematic study on their capability to model the motion patterns of people, without interactions with other individuals nor the social context. There is abundant literature on LSTMs, CNNs and GANs on this subject. However methods adopting Transformer techniques achieve great performances by complex models and a clear analysis of their adoption as plain sequence models is missing. This paper proposes the first in-depth study of Transformer Networks (TF) and the Bidirectional Transformers (BERT) for the forecasting of the individual motion of people, without bells and whistles. We conduct an exhaustive evaluation of the input/output representations, problem formulations and sequence modelling, including a novel analysis of their capability to predict multi-modal futures. Out of comparative evaluation on the ETH+UCY benchmark, both TF and BERT are top performers in predicting individual motions and remain within a narrow margin wrt more complex techniques, including both social interactions and scene contexts. Source code will be released for all conducted experiments.},
bibtex_show={true},
abbr={Pattern Recognition}
}




